{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyjsgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsgf\n",
    "from jsgf import PublicRule,Literal,Rule\n",
    "from jsgf import Grammar,grammars\n",
    "from jsgf import parser,parse_rule_string,expansions,parse_expansion_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule_compiled public <music_play> = [can you](put on| play)(<artist>|<song>);\n",
      "rule1_expansion Literal('[can you](put on| play)(<artist>|<song>)')\n",
      "rule1_string_generate [can you](put on| play)(<artist>|<song>)\n",
      "-------------------------------------------\n",
      "rule2_compiled public <artist> = beatles |radio head |cake |pink floyd;\n",
      "rule2_expansion Literal('beatles |radio head |cake |pink floyd')\n",
      "rule2_string beatles |radio head |cake |pink floyd\n"
     ]
    }
   ],
   "source": [
    "rule1=PublicRule(name='music_play',expansion='[can you](put on| play)(<artist>|<song>)')\n",
    "rule2=Rule(name='artist',visible=True,expansion='beatles |radio head |cake |pink floyd')\n",
    "rule3=Rule(name='song',visible=True,expansion='confortably numb |paranoid android |let it be |hey jude')\n",
    "\n",
    "rule1_compiled=rule1.compile(ignore_tags=True)\n",
    "print('rule_compiled',rule1_compiled)\n",
    "rule1_expanded=rule1.expansion\n",
    "print('rule1_expansion',rule1_expanded)\n",
    "rule1_sring_expand=rule1_expanded.generate()\n",
    "print('rule1_string_generate',rule1_sring_expand)\n",
    "\n",
    "print('-------------------------------------------')\n",
    "\n",
    "rule2_compiled=rule2.compile()\n",
    "print('rule2_compiled',rule2_compiled)\n",
    "rule2_expanded=rule2.expansion\n",
    "print('rule2_expansion',rule2_expanded)\n",
    "rule2_string_expand=rule2_expanded.generate()\n",
    "print('rule2_string',rule2_string_expand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itertools.product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled_grammar\n",
      " #JSGF V1.0;\n",
      "grammar music_play;\n",
      "public <music_play> = [can you](put on| play)(<artist>|<song>);\n",
      "public <artist> = beatles |radio head |cake |pink floyd;\n",
      "public <song> = confortably numb |paranoid android |let it be |hey jude;\n",
      "\n",
      "parsed_grammar\n",
      " Grammar(version=1.0, charset=<auto>, language=<auto>, name=music_play)\n"
     ]
    }
   ],
   "source": [
    "grammar=Grammar('music_play')\n",
    "grammar.add_rules(rule1,rule2,rule3)\n",
    "\n",
    "compiled_grammar=grammar.compile()\n",
    "print('compiled_grammar\\n',compiled_grammar)\n",
    "\n",
    "parsed_grammer=parser.parse_grammar_string(compiled_grammar)\n",
    "print('parsed_grammar\\n',parsed_grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(OptionalGrouping(Literal('can you')), ParsedAlternativeSet(Literal('put on'), Literal('play')), ParsedAlternativeSet(NamedRuleRef('artist'), NamedRuleRef('song')))\n"
     ]
    }
   ],
   "source": [
    "for rule in parsed_grammer.rules:\n",
    "    seq=rule.expansion\n",
    "    print(seq)\n",
    "\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PublicRule(name='music_play', expansion=Literal('[can you](put on| play)(<artist>|<song>)')) \n",
      " Literal('[can you](put on| play)(<artist>|<song>)')\n"
     ]
    }
   ],
   "source": [
    "for rule in grammar.rules:\n",
    "    print(rule,'\\n',rule.expansion)\n",
    "    \n",
    "    break\n",
    "    \n",
    "#     print(expansions.Expansion.generate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expansions.Literal(rule.expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function PublicRule.__reduce__()>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule1.__reduce__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar for handling Next level of Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "public <music_play> =\n",
    "[i want to listen to] (<genre> | <song> | <album> |<artist>) [music]\n",
    "[play me] (<song> | <album>) [by] (<artist>);\n",
    "\n",
    "<artist> =\n",
    "\n",
    "beatles |\n",
    "\n",
    "radio head |\n",
    "\n",
    "cake |\n",
    "\n",
    "pink floyd;\n",
    "\n",
    "<song> =\n",
    "\n",
    "comfortably numb |\n",
    "\n",
    "paranoid android |\n",
    "\n",
    "let it be |\n",
    "\n",
    "hey jude;\n",
    "\n",
    "<genre> =\n",
    "\n",
    "jazz;\n",
    "\n",
    "<album> =ummagumma;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated Utterances\n",
    "File is too big so is stored in text file as Recursive Utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Handle unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _compile_literal(self, element, *args, **kwargs):\n",
    "    # Build literals as sequences and use <NULL> for unknown words.\n",
    "    children = []\n",
    "    for word in element.words:\n",
    "        if self.engine.check_valid_word(word):\n",
    "            children.append(jsgf.Literal(word))\n",
    "        else:\n",
    "            children.append(self.compile_element(elements_.Impossible(), *args, **kwargs))\n",
    "\n",
    "            # Save the unknown word.\n",
    "            args[1].add(word)\n",
    "\n",
    "    return jsgf.Sequence(*children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples to know workflows\n",
    "#### git repo link\n",
    "#### https://github.com/Danesprite/pyjsgf/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PublicRule(name='command', expansion=Sequence(AlternativeSet(Literal('open'), Literal('close')), Literal('the file')))\n",
      "Tags: ['OPEN', 'CLOSE']\n",
      "\n",
      "Compiled grammar is:\n",
      "#JSGF V1.0;\n",
      "grammar default;\n",
      "public <command> = (open { OPEN }|close { CLOSE }) the file;\n",
      "\n",
      "Tagged rules are:\n",
      "[PublicRule(name='command', expansion=Sequence(AlternativeSet(Literal('open'), Literal('close')), Literal('the file')))]\n",
      "\n",
      "Tagged rules are:\n",
      "[PublicRule(name='command', expansion=Sequence(AlternativeSet(Literal('open'), Literal('close')), Literal('the file')))]\n",
      "\n",
      "Tags matching 'open the file' are: ['OPEN']\n",
      "generated:: close the file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from jsgf import PublicRule, Grammar, AlternativeSet, Literal, Sequence\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define a open/close file rule.\n",
    "    open, close = Literal(\"open\"), Literal(\"close\")\n",
    "    open.tag, close.tag = \"OPEN\", \"CLOSE\"\n",
    "    cmd = PublicRule(\"command\", Sequence(AlternativeSet(open, close), \"the file\"))\n",
    "    print(cmd)\n",
    "    # Print the tags of the 'command' rule.\n",
    "    print(\"Tags: %s\\n\" % cmd.tags)\n",
    "\n",
    "    # Initialise a new grammar and add the rule to it.\n",
    "    g = Grammar()\n",
    "    g.add_rule(cmd)\n",
    "\n",
    "    # Print the compiled grammar\n",
    "    print(\"Compiled grammar is:\\n%s\" % g.compile())\n",
    "\n",
    "    # Find and print rules tagged with \"OPEN\"\n",
    "    print(\"Tagged rules are:\\n%s\\n\" % g.find_tagged_rules(\"OPEN\"))\n",
    "    print(\"Tagged rules are:\\n%s\\n\" % g.find_tagged_rules(\"CLOSE\"))\n",
    "        \n",
    "        \n",
    "    # Matching tags can be retrieved using r.get_tags_matching\n",
    "    # The Rule.matched_tags property can also be used if Rule.matches or\n",
    "    # Grammar.find_matching_rules has been called first.\n",
    "    speech = \"open the file\"\n",
    "    print(\"Tags matching '%s' are: %s\" % (speech, cmd.get_tags_matching(speech)))\n",
    "    print('generated::',cmd.generate())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PublicRule(name='music_play', expansion=Literal('[can you](put on| play)(<artist>|<song>)'))\n",
      "current_match values before matching: [None]\n",
      "current_match values after matching: [None]\n",
      "Literal('[can you](put on| play)(<artist>|<song>)')\n",
      "indention and ancestorsLiteral('[can you](put on| play)(<artist>|<song>)')\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\"\"\"\n",
    "Example showing use of some recursive expansion functions.\n",
    "\"\"\"\n",
    "from jsgf import *\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create a new public rule using speech alternatives.\n",
    "#     rule = PublicRule(\"greet\", Sequence(AlternativeSet(\"hello\", \"hey\"), \"there\"))\n",
    "    rule=rule1\n",
    "    print(rule1)\n",
    "    # Define a function to get the rule's current_match values using\n",
    "    # flat_map_expansion.\n",
    "    def get_values():\n",
    "        return flat_map_expansion(rule.expansion, lambda x: x.current_match)\n",
    "\n",
    "    # All values will initially be set to None.\n",
    "    print(\"current_match values before matching: %s\" % get_values())\n",
    "\n",
    "    # Match a speech string and print the values again.\n",
    "    rule.matches(\"hello there\")\n",
    "    print(\"current_match values after matching: %s\" % get_values())\n",
    "\n",
    "    # Use filter_expansion to get expansions with no current_match value.\n",
    "    # This will get Literal(\"hey\") which wasn't matched.\n",
    "    print(filter_expansion(rule.expansion, lambda x: not x.current_match)[0])\n",
    "\n",
    "    # Use map_expansion to print a representation of the rule's expansion tree\n",
    "    def f(x):\n",
    "        # Print the expansion with an indentation based on the number of\n",
    "        # ancestors\n",
    "        n, p = 0, x.parent\n",
    "        while p:\n",
    "            n += 4\n",
    "            p = p.parent\n",
    "\n",
    "        print(\"indention and ancestors%s%s\" % (\" \" * n, x))\n",
    "\n",
    "    map_expansion(rule.expansion, f)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar(version=1.0, charset=UTF-8, language=en, name=example)\n",
      "Matching rule: Rule(name='greet', visible=True, expansion=Literal('hello world'))\n",
      "Matched tags: ['greeting']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example use of the pyjsgf parse_grammar_string function.\n",
    "The parse_grammar_file, parse_rule_string and parse_expansion_string functions\n",
    "are also available and work in a similar way.\n",
    "\"\"\"\n",
    "\n",
    "from jsgf import parse_grammar_string\n",
    "\n",
    "# Parse a grammar string with parse_grammar_string and get a Grammar object back.\n",
    "grammar = parse_grammar_string(\n",
    "    \"#JSGF V1.0 UTF-8 en;\"\n",
    "    \"grammar example;\"\n",
    "    \"public <greet> = hello world {greeting};\"\n",
    ")\n",
    "\n",
    "# Print it.\n",
    "print(grammar)\n",
    "\n",
    "# Get the rule that matches \"hello world\".\n",
    "rule = grammar.find_matching_rules(\"hello world\")[0]\n",
    "print(\"Matching rule: %s\" % rule)\n",
    "\n",
    "# Tags are also parsed and will work as expected.\n",
    "print(\"Matched tags: %s\" % rule.matched_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used for Our Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dragonfly2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.29.0)\n",
      "Requirement already satisfied: comtypes; platform_system == \"Windows\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (1.1.7)\n",
      "Requirement already satisfied: packaging>=19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (20.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (4.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (2.24.0)\n",
      "Requirement already satisfied: Werkzeug in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (2020.6.8)\n",
      "Requirement already satisfied: json-rpc in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (1.13.0)\n",
      "Requirement already satisfied: lark-parser==0.8.* in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (0.8.9)\n",
      "Requirement already satisfied: pywin32; platform_system == \"Windows\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (227)\n",
      "Requirement already satisfied: setuptools>=40.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pyperclip>=1.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (1.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dragonfly2) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=19.0->dragonfly2) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->dragonfly2) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->dragonfly2) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->dragonfly2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->dragonfly2) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install dragonfly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dragonfly.parser as dparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonfly import ElementBase,Rule,Grammar,grammar\n",
    "import dragonfly.grammar.elements as elements_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "drag_grammar=Grammar('music_play')\n",
    "drag_rule2=Rule(name='artist',visible=True,expansion='beatles |radio head |cake |pink floyd')\n",
    "drag_rule3=Rule(name='song',visible=True,expansion='confortably numb |paranoid android |let it be |hey jude')\n",
    "drag_grammar.add_rules(drag_rule2,drag_rule3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keyword spotting for multiple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sphinxwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from dragonfly import Grammar, CompoundRule, Dictation, get_engine\n",
    "# engine = get_engine(\"sphinx\")\n",
    "# engine.config.START_ASLEEP = False\n",
    "# class MyRule(CompoundRule):\n",
    "#     spec = \"hello <text>\"\n",
    "#     extras = [Dictation(\"text\")]\n",
    "#     def _process_recognition(self, node, extras):\n",
    "#         # \"world\" will be printed in lowercase to be consistent with\n",
    "#         # normal output from CMU Pocket Sphinx.\n",
    "#         print(extras[\"text\"])\n",
    "# grammar = Grammar(\"dictation grammar\")\n",
    "# grammar.add_rule(MyRule())\n",
    "# grammar.load()\n",
    "# engine.mimic(\"hello WORLD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"majhe nav Vikas ahe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मझे नव् Vइकस् अहे\n"
     ]
    }
   ],
   "source": [
    "print(transliterate(a, sanscript.HK, sanscript.DEVANAGARI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The Grammar\n",
    "\n",
    "Let's cover the grammar very quickly: The Devanagari Block. As a developer, there are two character classes you'll want to concern yourself with:\n",
    "\n",
    "Sign: This is a character that affects a previously-occurring character. Example, this character: ्. The light-colored circle indicates the location of the center of the character it is to be placed upon.\n",
    "Letter / Vowel / Other: This is a character that may be affected by signs. Example, this character: क.\n",
    "Combination result of ् and क: क्. But combinations can extend, so क् and षति will actually become क्षति (in this case, we right-rotate the first character by 90 degrees, modify some of the stylish elements, and attach it at the left side of the second character).\n",
    "\n",
    "My answer here is not to solve the situation of these infinite (and tremendously beautiful) combinations, but simply clusters of singular letters and/or clusters of singular letters with their affecting, sign characters. If we are thinking \"what are the characters of this Devanagari string?\", then this is the right way to go, otherwise any combination of letters would form a unique character of a unique length, and then most of the concepts and algorithms associated with letter-systems would fail.\n",
    "\n",
    "So, for instance, a symbol word would be...\n",
    "\n",
    "(letter) (letter) (sign) (sign) (letter) (sign)\n",
    "In this case, you'll want the result...\n",
    "\n",
    "[\n",
    "    0=>(letter),\n",
    "    1=>(letter) (sign) (sign),\n",
    "    2=>(letter) (sign),\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
