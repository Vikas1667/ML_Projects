{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034b2f98",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### [AWS sagemaker MLOPs](https://docs.aws.amazon.com/sagemaker/latest/dg/mlops.html)\n",
    "\n",
    "### Sagemaker Steps \n",
    "\n",
    "- Create a model in SageMaker Inference by pointing to model artifacts stored in Amazon S3 and a container image.\n",
    "- Select an inference option. For more information, see Inference options.\n",
    "- Create a SageMaker Inference endpoint configuration by choosing the instance type and number of instances you need behind the endpoint. You can use Amazon SageMaker Inference Recommender to get recommendations for instance types. For Serverless Inference, you only need to provide the memory configuration you need based on your model size.\n",
    "- Create a SageMaker Inference endpoint.\n",
    "- Invoke your endpoint to receive an inference as a response.\n",
    "\n",
    "\n",
    "### Sagemaker experiments : Track experiments for ML processes \n",
    "\n",
    "### Workflows\n",
    "    \n",
    "1. Pipelines: \n",
    "    *  Amazon SageMaker Model Building Pipelines pipeline is a series of interconnected steps that are defined using the Pipelines SDK. \n",
    "    * You can also build your pipeline without the SDK using the pipeline definition JSON schema. \n",
    "    * This pipeline definition encodes a pipeline using a directed acyclic graph (DAG) that can be exported as a JSON             definition.  \n",
    "    * This DAG gives information on the requirements for and relationships between each step of your pipeline. The               structure of a pipeline's DAG is determined by the data dependencies between steps. \n",
    "    * These data dependencies are created when the properties of a step's output are passed as the input to another step.         The following image is an example of a pipeline DAG:\n",
    "\n",
    "    * An Amazon SageMaker Model Building Pipelines instance is composed of a name, parameters, and steps. Pipeline names must be unique within an (account, region) pair.\n",
    "\n",
    "2. Pipeline steps\n",
    "    - Step Types\n",
    "    - Step Properties\n",
    "    - Step Parallelism\n",
    "    - Data Dependency Between Steps\n",
    "    - Custom Dependency Between Steps\n",
    "    - Use a Custom Image in a Step\n",
    "\n",
    "3. Parameter supports\n",
    "    - ParameterString – Representing a string parameter.\n",
    "\n",
    "    - ParameterInteger – Representing an integer parameter.\n",
    "\n",
    "    - ParameterFloat – Representing a float parameter.\n",
    "\n",
    "    - ParameterBoolean – Representing a Boolean Python type.\n",
    "\n",
    "Note: As you use SageMaker Pipelines to create workflows and orchestrate your ML training steps, you might need to undertake multiple experimentation phases. Instead of running the entire pipeline from start to finish, you might only want to iterate over particular steps. SageMaker Pipelines supports selective execution of pipeline steps to help you optimize your ML training.for more refer \n",
    "[Selective execution of pipeline steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-selective-ex.html)\n",
    "      \n",
    "      \n",
    "### Deploy model for inference \n",
    "Amazon SageMaker offers the following four options to deploy models for inference.\n",
    "\n",
    "- Real-time inference for inference workloads with real-time, interactive, low latency requirements.\n",
    "\n",
    "- Batch transform for offline inference with large datasets.\n",
    "\n",
    "- Asynchronous inference for near-real-time inference with large inputs that require longer preprocessing times.\n",
    "\n",
    "- Serverless inference for inference workloads that have idle periods between traffic spurts.\n",
    "\n",
    "[feature matrix for comparisions](https://docs.aws.amazon.com/sagemaker/latest/dg/model-deploy-feature-matrix.html)\n",
    "\n",
    "\n",
    "### Register and Deploy Models with Model Registry\n",
    "1) [Model group](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-model-group.html): A Model Group contains a group of versioned models. Create a Model Group by using either the AWS SDK for Python (Boto3) or the Amazon SageMaker Studio console.\n",
    "\n",
    "2) [Register model version](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-version.html)\n",
    "\n",
    "     You can register an Amazon SageMaker model by creating a model version that specifies the model group to which it          belongs. A model version must include both the model artifacts (the trained weights of a model) and the inference code      for the model.\n",
    "3) [Deploy model from registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy.html)\n",
    "\n",
    "\n",
    "### Tracking and troubleshoot Sagemaker  \n",
    "\n",
    "Lineage tracking in Studio is centered around a directed acyclic graph (DAG). The DAG represents the steps in a pipeline. From the DAG you can track the lineage from any step to any other step.   \n",
    "   - [Lineage steps link](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-lineage-tracking.html)\n",
    "   - [deployment troubleshoot](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model-reference.html)\n",
    "   \n",
    "### [Project Template](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-sm.html) \n",
    "\n",
    "Amazon SageMaker provides project templates that create the infrastructure you need to create an MLOps solution for continuous integration and continuous deployment (CI/CD) of ML models. Use these templates to process data, extract features, train and test models, register the models in the SageMaker model registry, and deploy the models for inference. You can customize the seed code and the configuration files to suit your requirements.\n",
    "\n",
    "   \n",
    "\n",
    "### [MLOps Workload Orchestrator](https://docs.aws.amazon.com/solutions/latest/mlops-workload-orchestrator/solution-overview.html)\n",
    "\n",
    "Deploy a robust pipeline that uses managed automation tools and machine learning (ML) services to simplify ML model\n",
    "development and production\n",
    "   \n",
    "###  [FAQS](https://docs.aws.amazon.com/sagemaker/latest/dg/mlopsfaq.html)\n",
    "\n",
    "    1. what is step decorator and when to use it? \n",
    "    2. How to pass data between steps \n",
    "    3. How to troubleshoot the MLOPs or how to identify MLOPs pipeline fails\n",
    "    4. how to Define a sagemaker Pipeline and all featres\n",
    "    5. how to track pipeline \n",
    "\n",
    "\n",
    "### usecases and start to build\n",
    "1. [Automate Machine Learning Workflows steps](https://aws.amazon.com/tutorials/machine-learning-tutorial-mlops-automate-ml-workflows/)  \n",
    "\n",
    "2. [Sagemaker Deployment Tutorial using realtime inference build and tested](https://aws.amazon.com/tutorials/machine-learning-tutorial-deploy-model-to-real-time-inference-endpoint/)\n",
    "\n",
    "3. [xgboost_customer_churn_studio](https://github.com/aws/amazon-sagemaker-examples/blob/main/aws_sagemaker_studio/getting_started/xgboost_customer_churn_studio.ipynb)\n",
    "\n",
    "4. [fraud detection](https://github.com/aws/amazon-sagemaker-examples/tree/main/end_to_end/fraud_detection)\n",
    "\n",
    "5. [Sagemaker and gitlabs](https://aws.amazon.com/blogs/machine-learning/build-mlops-workflows-with-amazon-sagemaker-projects-gitlab-and-gitlab-pipelines)\n",
    "\n",
    "6. [Gitlab and sagemaker](https://github.com/aws-samples/sagemaker-custom-project-templates/tree/main/mlops-template-gitlab)\n",
    "\n",
    "7. [MLOPs reference](https://towardsdatascience.com/a-practical-guide-to-mlops-in-aws-sagemaker-part-i-1d28003f565)\n",
    "\n",
    "8. [NLP Sentiment MLOPs](https://github.com/aws/amazon-sagemaker-examples/tree/main/end_to_end/nlp_mlops_company_sentiment)\n",
    "    1. Model: FinBERT\n",
    "    2. Dataset: NewsCatcher API \n",
    "\n",
    "9. [Comparing model metrics with SageMaker Pipelines and SageMaker Model Registry](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-pipeline-compare-model-versions/notebook.ipynb)\n",
    "\n",
    "10. [Build machine learning workflows with Amazon SageMaker Processing and AWS Step Functions Data Science SDK](https://github.com/aws/amazon-sagemaker-examples/blob/main/step-functions-data-science-sdk/step_functions_mlworkflow_processing/step_functions_mlworkflow_scikit_learn_data_processing_and_model_evaluation.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c7388",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0d664a",
   "metadata": {},
   "source": [
    "## Other components \n",
    "\n",
    "### S3 Storage classes \n",
    "- S3 Standard\n",
    "- S3 Standard-Infrequent Access (IA)\n",
    "- S3 One Zone-Infrequent Access (IA)\n",
    "- S3 Glacier Instant Retrieval\n",
    "- S3 Glacier Flexible Retrieval\n",
    "- S3 Glacier Deep Archive\n",
    "\n",
    "\n",
    "### Shadow tests \n",
    "\n",
    "With Amazon SageMaker you can evaluate any changes to your model serving infrastructure by comparing its performance against the currently deployed infrastructure.\n",
    "\n",
    "\n",
    "### [CORS](https://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html)\n",
    "\n",
    "### [Data Encryption](https://docs.aws.amazon.com/whitepapers/latest/logical-separation/encrypting-data-at-rest-and--in-transit.html)\n",
    "\n",
    "### [Step Functions](https://aws.amazon.com/step-functions/)\n",
    "\n",
    "AWS Step Functions provides serverless orchestration for modern applications. Orchestration centrally manages a workflow by breaking it into multiple steps, adding flow logic, and tracking the inputs and outputs between the steps.\n",
    "explore the step functions usecases [here](https://aws.amazon.com/step-functions/use-cases/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad95efe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### AWS Lambda(https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)\n",
    "\n",
    "- AWS Lambda is a compute service that lets you run code without provisioning or managing servers.\n",
    "\n",
    "https://www.youtube.com/watch?v=EBSdyoO3goc\n",
    "\n",
    "4 guildine\n",
    "1. no server for provision and maintainence\n",
    "2. scale with usage\n",
    "3. pay for value\n",
    "4. availability and fault tolerence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### AWS Lambda\n",
    "\n",
    "AWS Lambda is a serverless computing service provided by Amazon Web Services (AWS). Users of AWS Lambda create functions, self-contained applications written in one of the supported languages and runtimes, and upload them to AWS Lambda, which executes those functions in an efficient and flexible manner clearly explained [official here](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) and also define [here](https://www.serverless.com/aws-lambda)   \n",
    "for python implementation mention [here](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)\n",
    "and [lambda handler](https://docs.aws.amazon.com/lambda/latest/dg/python-handler.html)\n",
    "\n",
    "\n",
    "##### Calling Sagemaker endpoint using AWS API gateway and Lambda\n",
    "The following diagram shows how the deployed model is called using serverless architecture. Starting from the client side, a client script calls an Amazon API Gateway API action and passes parameter values. API Gateway is a layer that provides the API to the client. In addition, it seals the backend so that AWS Lambda stays and runs in a protected private network. API Gateway passes the parameter values to the Lambda function. The Lambda function parses the value and sends it to the SageMaker model endpoint. The model performs the prediction and returns the predicted value to Lambda. The Lambda function parses the returned value and sends it back to API Gateway. \n",
    "API Gateway responds to the client with that value.\n",
    "\n",
    "[Calling Sagemaker endpoint using AWS API gateway and Lambda](https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/)\n",
    "\n",
    "![AWS serverless](./predictive_maintainence/images/serverless_architecture.jpg)\n",
    "\n",
    "\n",
    "\n",
    "##### Lambda function for processing input data\n",
    "\n",
    "Creae Batch transformer function \\\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html\n",
    "\n",
    "[preprocessing using Lambda](https://docs.aws.amazon.com/kinesisanalytics/latest/dev/lambda-preprocessing.html)\n",
    "\n",
    "https://docs.aws.amazon.com/kinesisanalytics/latest/dev/lambda-preprocessing-functions.html\n",
    "\n",
    "#### Usecases\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae6034c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### [Amazon EC2](https://aws.amazon.com/ec2/instance-types/?gclid=Cj0KCQiAw6yuBhDrARIsACf94RV-ywvJfljJQeU5vQeEGV1HoHEOFMgxroK-Aftf2yL_yNZn_KR16j4aAshuEALw_wcB&trk=32f4fbd0-ffda-4695-a60c-8857fab7d0dd&sc_channel=ps&ef_id=Cj0KCQiAw6yuBhDrARIsACf94RV-ywvJfljJQeU5vQeEGV1HoHEOFMgxroK-Aftf2yL_yNZn_KR16j4aAshuEALw_wcB:G:s&s_kwcid=AL!4422!3!536392685920!e!!g!!ec2%20instance!11539707735!118057054048%3E)\n",
    "\n",
    "Amazon EC2 provides a wide selection of instance types optimized to fit different use cases. Instance types comprise varying combinations of CPU, memory, storage, and networking capacity and give you the flexibility to choose the appropriate mix of resources for your applications. Each instance type includes one or more instance sizes, allowing you to scale your resources to the requirements of your target workload.\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae21f6",
   "metadata": {},
   "source": [
    "### Unfolding usecases to get intuition to insight finally to workable solutions\n",
    "\n",
    "#### Build machine learning workflows with Amazon SageMaker Processing and AWS Step Functions Data Science SDK\n",
    "\n",
    "#### The high level steps include below -\n",
    "\t1. Run a SageMaker processing job using ProcessingStep of AWS Step Functions Data Science SDK to run a scikit-learn script that cleans, pre-processes, performs feature engineering, and splits the input data into train and test sets.\n",
    "\t2. Run a training job using TrainingStep of AWS Step Functions Data Science SDK on the pre-processed training data to train a model\n",
    "\t3. Run a processing job on the pre-processed test data to evaluate the trained model's performance using ProcessingStep of AWS Step Functions Data Science SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8b39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
