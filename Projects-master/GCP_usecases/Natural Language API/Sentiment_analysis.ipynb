{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt-text-1](../gcp.png \"GCP\") ![alt-text-2](../codelabs.png \"codelab\")\n",
    "<!-- ![codelabs](../codelabs.png) -->\n",
    "\n",
    "## https://codelabs.developers.google.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import language_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Natural Language API with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://codelabs.developers.google.com/codelabs/cloud-natural-language-python3#1\n",
    "\n",
    "## Setup \n",
    "\n",
    "### Setup and requirements\n",
    "Self-paced environment setup\n",
    "Start Cloud Shell\n",
    "\n",
    "### Enable the API\n",
    "gcloud services enable language.googleapis.com\n",
    "\n",
    "### Authenticate API requests\n",
    "\n",
    "In order to make requests to the Natural Language API, you need to use a Service Account. A Service Account belongs to your project and it is used by the Python client library to make Natural Language API requests. Like any other user account, a service account is represented by an email address. In this section, you will use the Cloud SDK to create a service account and then create credentials you will need to authenticate as the service account.\n",
    "\n",
    "First, set a PROJECT_ID environment variable:\n",
    "\n",
    "\n",
    "export PROJECT_ID=$(gcloud config get-value core/project)\n",
    "Next, create a new service account to access the Natural Language API by using:\n",
    "\n",
    "\n",
    "gcloud iam service-accounts create my-nl-sa \\\n",
    "  --display-name \"my nl service account\"\n",
    "Next, create credentials that your Python code will use to login as your new service account. Create and save these credentials as a ~/key.json JSON file by using the following command:\n",
    "\n",
    "\n",
    "gcloud iam service-accounts keys create ~/key.json \\\n",
    "  --iam-account  my-nl-sa@${PROJECT_ID}.iam.gserviceaccount.com\n",
    "Finally, set the GOOGLE_APPLICATION_CREDENTIALS environment variable, which is used by the Natural Language API Python library, covered in the next step, to find your credentials. The environment variable should be set to the full path of the credentials JSON file you created, by using:\n",
    "\n",
    "\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=~/key.json\n",
    "\n",
    "\n",
    "### Install the client library\n",
    "\n",
    "You're going to use the Google Cloud Python client library, which should already be installed in your Cloud Shell environment. You can read more about Google Cloud Python services here.\n",
    "\n",
    "Check that the client library is already installed:\n",
    "\n",
    "\n",
    "pip3 freeze | grep google-cloud-language\n",
    "You should see something similar to:\n",
    "\n",
    "\n",
    "google-cloud-language==2.0.0\n",
    "Note: If you're setting up your own Python development environment, you can follow these guidelines. You can then install (or update) the Natural Language API client library with pip3:\n",
    "\n",
    "pip3 install --user --upgrade google-cloud-language\n",
    "\n",
    "...\n",
    "\n",
    "Successfully installed google-cloud-language-2.0.0\n",
    "\n",
    "\n",
    "\n",
    "### Start Interactive Python\n",
    "In this tutorial, you'll use an interactive Python interpreter called IPython, which is preinstalled in Cloud Shell. Start a session by running ipython in Cloud Shell:\n",
    "\n",
    "\n",
    "ipython\n",
    "You should see something like this:\n",
    "\n",
    "\n",
    "Python 3.7.3 (default, Jul 25 2020, 13:03:44)\n",
    "Type 'copyright', 'credits' or 'license' for more information\n",
    "IPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\n",
    "\n",
    "In [1]:\n",
    "Note: If needed, you can quit your IPython session with the exit command.\n",
    "\n",
    "\n",
    "### Sentiment analysis\n",
    "In this section, you will perform Sentiment Analysis on a string and find out the Score and Magnitude using the Natural Language API.\n",
    "\n",
    "The Score of the sentiment ranges between -1.0 (negative) and 1.0 (positive) and corresponds to the overall sentiment from the given information.\n",
    "\n",
    "The Magnitude of the sentiment ranges from 0.0 to +infinity and indicates the overall strength of sentiment from the given information. The more information that is provided the higher the magnitude.\n",
    "\n",
    "Copy the following code into your IPython session:\n",
    "\n",
    "\n",
    "from google.cloud import language\n",
    "\n",
    "\n",
    "def analyze_text_sentiment(text):\n",
    "    client = language.LanguageServiceClient()\n",
    "    document = language.Document(content=text, type_=language.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    response = client.analyze_sentiment(document=document)\n",
    "\n",
    "    sentiment = response.document_sentiment\n",
    "    results = dict(\n",
    "        text=text,\n",
    "        score=f\"{sentiment.score:.1%}\",\n",
    "        magnitude=f\"{sentiment.magnitude:.1%}\",\n",
    "    )\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k:10}: {v}\")\n",
    "Call the function:\n",
    "\n",
    "\n",
    "text = \"Guido van Rossum is great!\"\n",
    "analyze_text_sentiment(text)\n",
    "You should see the following output:\n",
    "\n",
    "\n",
    "text      : Guido van Rossum is great!\n",
    "score     : 90.0%\n",
    "magnitude : 90.0%\n",
    "\n",
    "Sentiment Analysis\n",
    "https://cloud.google.com/natural-language/docs/basics#sentiment_analysis\n",
    "\n",
    "###  Entity analysis\n",
    "Entity Analysis inspects the given information for entities by searching for proper nouns such as public figures, landmarks, etc., and returns information about those entities.\n",
    "\n",
    "Copy the following code into your IPython session:\n",
    "\n",
    "\n",
    "from google.cloud import language\n",
    "\n",
    "\n",
    "def analyze_text_entities(text):\n",
    "    client = language.LanguageServiceClient()\n",
    "    document = language.Document(content=text, type_=language.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    response = client.analyze_entities(document=document)\n",
    "\n",
    "    for entity in response.entities:\n",
    "        print(\"=\" * 80)\n",
    "        results = dict(\n",
    "            name=entity.name,\n",
    "            type=entity.type_.name,\n",
    "            salience=f\"{entity.salience:.1%}\",\n",
    "            wikipedia_url=entity.metadata.get(\"wikipedia_url\", \"-\"),\n",
    "            mid=entity.metadata.get(\"mid\", \"-\"),\n",
    "        )\n",
    "        for k, v in results.items():\n",
    "            print(f\"{k:15}: {v}\")\n",
    "Call the function:\n",
    "\n",
    "\n",
    "text = \"Guido van Rossum is great, and so is Python!\"\n",
    "analyze_text_entities(text)\n",
    "You should see the following output:\n",
    "\n",
    "\n",
    "================================================================================\n",
    "name           : Guido van Rossum\n",
    "type           : PERSON\n",
    "salience       : 65.8%\n",
    "wikipedia_url  : https://en.wikipedia.org/wiki/Guido_van_Rossum\n",
    "mid            : /m/01h05c\n",
    "\n",
    "\n",
    "================================================================================\n",
    "name           : Python\n",
    "type           : ORGANIZATION\n",
    "salience       : 34.2%\n",
    "wikipedia_url  : https://en.wikipedia.org/wiki/Python_(programming_language)\n",
    "mid            : /m/05z1_\n",
    "Take a moment to test your own sentences mentioning other entities.\n",
    "\n",
    "Entity Analysis\n",
    "https://cloud.google.com/natural-language/docs/basics#entity_analysis\n",
    "\n",
    "\n",
    "###  Syntax analysis\n",
    "Syntactic Analysis extracts linguistic information, breaking up the given text into a series of sentences and tokens (generally, word boundaries), providing further analysis on those tokens.\n",
    "\n",
    "This example will print out the number of sentences, tokens, and provide the part of speech for each token.\n",
    "\n",
    "Copy the following code into your IPython session:\n",
    "\n",
    "\n",
    "from google.cloud import language\n",
    "\n",
    "\n",
    "def analyze_text_syntax(text):\n",
    "    client = language.LanguageServiceClient()\n",
    "    document = language.Document(content=text, type_=language.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    response = client.analyze_syntax(document=document)\n",
    "\n",
    "    fmts = \"{:10}: {}\"\n",
    "    print(fmts.format(\"sentences\", len(response.sentences)))\n",
    "    print(fmts.format(\"tokens\", len(response.tokens)))\n",
    "    for token in response.tokens:\n",
    "        print(fmts.format(token.part_of_speech.tag.name, token.text.content))\n",
    "Call the function:\n",
    "\n",
    "\n",
    "text = \"Guido van Rossum is great!\"\n",
    "analyze_text_syntax(text)\n",
    "You should see the following output:\n",
    "\n",
    "\n",
    "sentences : 1\n",
    "tokens    : 6\n",
    "NOUN      : Guido\n",
    "NOUN      : van\n",
    "NOUN      : Rossum\n",
    "VERB      : is\n",
    "ADJ       : great\n",
    "PUNCT     : !\n",
    "Take a moment to test your own sentences with other syntactic structures.\n",
    "\n",
    "Here is a visual interpretation showing the complete syntactic analysis:\n",
    "\n",
    "6404071908be58df.png\n",
    "\n",
    "Note: You can create your own parse trees with the Natural Language demo available here: https://cloud.google.com/natural-language/.\n",
    "\n",
    "Syntax analysis\n",
    "https://cloud.google.com/natural-language/docs/basics#syntactic_analysis\n",
    "\n",
    "\n",
    "###  Content classification\n",
    "Content Classification analyzes a document and return a list of content categories that apply to the text found in the document.\n",
    "\n",
    "This example will print out the categories that apply to a description of the Python language.\n",
    "\n",
    "Copy the following code into your IPython session:\n",
    "\n",
    "\n",
    "from google.cloud import language\n",
    "\n",
    "\n",
    "def classify_text(text):\n",
    "    client = language.LanguageServiceClient()\n",
    "    document = language.Document(content=text, type_=language.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    response = client.classify_text(document=document)\n",
    "\n",
    "    for category in response.categories:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"category  : {category.name}\")\n",
    "        print(f\"confidence: {category.confidence:.0%}\")\n",
    "Call the function:\n",
    "\n",
    "\n",
    "text = (\n",
    "    \"Python is an interpreted, high-level, general-purpose programming language. \"\n",
    "    \"Created by Guido van Rossum and first released in 1991, \"\n",
    "    \"Python's design philosophy emphasizes code readability \"\n",
    "    \"with its notable use of significant whitespace.\"\n",
    ")\n",
    "classify_text(text)\n",
    "You should see the following output:\n",
    "\n",
    "\n",
    "================================================================================\n",
    "category  : /Computers & Electronics/Programming\n",
    "confidence: 99%\n",
    "\n",
    "================================================================================\n",
    "\n",
    "category  : /Science/Computer Science\n",
    "confidence: 99%\n",
    "Take a moment to test your own sentences relating to other categories. A complete list of content categories can be found here.\n",
    "\n",
    "Note: You must supply a text block (document) with at least twenty tokens (words).\n",
    "\n",
    "content classification\n",
    "https://cloud.google.com/natural-language/docs/basics#content-classification\n",
    "\n",
    "\n",
    "\n",
    "### Learn More\n",
    "11. Congratulations!\n",
    "You learned how to use the Natural Language API using Python!\n",
    "\n",
    "Clean up\n",
    "To avoid incurring charges to your Google Cloud account for the resources used in this tutorial:\n",
    "\n",
    "In the Cloud Console, go to the Manage resources page.\n",
    "In the project list, select your project then click Delete.\n",
    "In the dialog, type the project ID and then click Shut down to delete the project.\n",
    "Learn more\n",
    "\n",
    "Test the demo in your browser: https://cloud.google.com/ml-onramp/natural-language\n",
    "\n",
    "Natural Language documentation: https://cloud.google.com/natural-language/docs/\n",
    "\n",
    "Python on Google Cloud: https://cloud.google.com/python/\n",
    "\n",
    "Cloud Client Libraries for Python: https://googlecloudplatform.github.io/google-cloud-python/\n",
    "\n",
    "License\n",
    "This work is licensed under a Creative Commons Attribution 2.0 Generic License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping models in AI Platform Notebooks\n",
    "\n",
    "https://codelabs.developers.google.com/codelabs/prototyping-caip-notebooks?hl=en#0\n",
    "\n",
    "\n",
    "### Overview\n",
    "This lab will walk you through various tools in AI Platform Notebooks for exploring your data and prototyping ML models.\n",
    "\n",
    "What you learn\n",
    "You'll learn how to:\n",
    "\n",
    "Create and customize an AI Platform Notebooks instance\n",
    "Track your notebooks code with git, directly integrated into AI Platform Notebooks\n",
    "Use the What-If Tool within your notebook\n",
    "The total cost to run this lab on Google Cloud is about $1. Full details on AI Platform Notebooks pricing can be found\n",
    "[here](https://cloud.google.com/vertex-ai/pricing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Instantiates a client\n",
    "\n",
    "# # credential_path = \"path/to/credientials/dir/stellar-aurora-304608-8d2c844e1912.json\"\n",
    "# credential_path = \"../../../../../GCP/shweta_key/stellar-aurora-304608-8d2c844e1912.json\"\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path\n",
    "# client = language_v1.LanguageServiceClient()\n",
    "# # The text to analyze\n",
    "# text = u\"Hello, world!\"\n",
    "# document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "# # Detects the sentiment of the text\n",
    "# sentiment = client.analyze_sentiment(request={'document': document}).document_sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hello, world!\n",
      "Sentiment: 0.6000000238418579, 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "print(\"Text: {}\".format(text))\n",
    "print(\"Sentiment: {}, {}\".format(sentiment.score, sentiment.magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
