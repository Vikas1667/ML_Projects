{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS\n",
    "https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-extract-content-from-pdf-files-using-amazon-textract.html\n",
    "\n",
    "https://docs.aws.amazon.com/AmazonS3/latest/userguide/IndexDocumentSupport.html\n",
    "\n",
    "https://www.gormanalysis.com/blog/connecting-to-aws-s3-with-python/\n",
    "https://realpython.com/python-boto3-aws-s3/\n",
    "\n",
    "\n",
    "#### Sagemaker\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-mlconcepts.html\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html\n",
    "\n",
    "starting Notebook\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html\n",
    "\n",
    "Git repo\n",
    "https://github.com/aws/amazon-sagemaker-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case\n",
    "\n",
    "## 1. Extract TextRact and Multi label Text classification \n",
    "### Problem Statement \n",
    "\n",
    "#### Extract text from pdf data using S3, Sagemaker and Textract\n",
    "\n",
    "#### Task\n",
    "\n",
    "1) Split large pdf stored in S3 into pages and store selected pages again to s3\n",
    "2) Use textract to extract text from pdf\n",
    "\n",
    "\n",
    "#### Approach\n",
    "1) Connect to s3 using python \n",
    "https://www.gormanalysis.com/blog/connecting-to-aws-s3-with-python/\n",
    "\n",
    "2) Create bucket and push pdf into bucket\n",
    "\n",
    "https://medium.com/@vishal.sharma./create-an-aws-s3-bucket-using-aws-cli-5a19bc1fda79\n",
    "\n",
    "3) Configure and setup Sagemaker notebook instance using Boto3 \n",
    "\n",
    "\n",
    "```python\n",
    "!pip install boto3\n",
    "import boto3\n",
    "\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-2',\n",
    "    aws_access_key_id='mykey',\n",
    "    aws_secret_access_key='mysecretkey'\n",
    ")\n",
    "\n",
    "or \n",
    "\n",
    "s3_client=boto3.client()\n",
    "response=s3_client.get_object(Bucket='bucketname',Key='filename')\n",
    "\n",
    "# S3 bucket identifier\n",
    "bucket = s3.Bucket(name=\"my_bucket\")\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "4) Load or Download pdf from s3 to Sagemaker notebook \\\n",
    "https://towardsdatascience.com/how-to-read-data-files-on-s3-from-amazon-sagemaker-f288850bfe8f\n",
    "\n",
    "\n",
    "5) Split pdf into pages and stored into s3 back again \\\n",
    "```python\n",
    "from pdfrw import PdfReader, PdfWriter\n",
    "```\n",
    "```python\n",
    "pages = PdfReader('inputfile.pdf').pages\n",
    "parts = [(3,6),(7,10)]\n",
    "for part in parts:\n",
    "    outdata = PdfWriter(f'pages_{part[0]}_{part[1]}.pdf')\n",
    "    for pagenum in range(*part):\n",
    "        outdata.addpage(pages[pagenum-1])\n",
    "    outdata.write()\n",
    "```\n",
    "\n",
    "#### Checks and Testing for performed task\n",
    "\n",
    "1) Testing Reading pdf from s3 \\\n",
    "\n",
    "\n",
    "```python\n",
    "!pip install pdfminer3 \n",
    "!pip install PyPDF2\n",
    "from pdfminer3.layout import LAParams, LTTextBox\n",
    "from pdfminer3.pdfpage import PDFPage\n",
    "from pdfminer3.pdfinterp import PDFResourceManager\n",
    "from pdfminer3.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer3.converter import PDFPageAggregator\n",
    "from pdfminer3.converter import TextConverter\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "resource_manager = PDFResourceManager()\n",
    "file_handle = io.StringIO()\n",
    "converter = TextConverter(resource_manager, file_handle, laparams=LAParams())\n",
    "page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "s3_client=boto3.client()\n",
    "response=s3_client.get_object(Bucket='bucketname',Key='filename')\n",
    "data = response['Body'].read()\n",
    "\n",
    "for page in PDFPage.get_pages(io.BytesIO(data)):\n",
    "    print(page)\n",
    "    processed_page=page_interpreter.process_page(io.BytesIO(data))\n",
    "    text=file_handle.getvalue()\n",
    "    print(text)\n",
    "    pdf=PDFPage.create_pages(text)\n",
    "    \n",
    "    output=PdffileWriter()\n",
    "    print(output)\n",
    "    \n",
    "    file='test.pdf'\n",
    "    s3.Bucket('Bucket_name').put_object(Key=file,Body=text)\n",
    "    break\n",
    "    \n",
    "```\n",
    "\n",
    "2) Reading pdf as to perform specific task\n",
    "```python\n",
    "#https://stackoverflow.com/questions/62799852/read-pdf-object-from-s3\n",
    "import boto3\n",
    "from PyPDF2 import PdfFileReader\n",
    "from io import BytesIO\n",
    "\n",
    "bucket_name =\"pdf-forms-bucket\"\n",
    "item_name = \"form.pdf\"\n",
    "\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "obj = s3.Object(bucket_name, item_name)\n",
    "fs = obj.get()['Body'].read()\n",
    "pdf = PdfFileReader(BytesIO(fs))\n",
    "\n",
    "data = pdf.getFormTextFields()\n",
    "```\n",
    "\n",
    "2) Testing various splitting pdf methods locally \n",
    "\n",
    "```python\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "\n",
    "inputpdf = PdfFileReader(open(\"/path to pdf file directory/pdf_name.pdf\", \"rb\"))\n",
    "\n",
    "for i in range(inputpdf.numPages):\n",
    "    output = PdfFileWriter()\n",
    "    output.addPage(inputpdf.getPage(i))\n",
    "    with open(\"document-page%s.pdf\" % i, \"wb\") as outputStream:\n",
    "        output.write(outputStream)\n",
    "```\n",
    "\n",
    "#### Issues \n",
    "https://stackoverflow.com/questions/65844539/how-to-use-pdfminer-to-extract-text-from-pdf-files-stored-in-s3-bucket-without-delattr \\\n",
    "https://stackoverflow.com/questions/66206423/how-to-upload-a-pdfusing-pdfpages-to-aws-s3-in-python \\\n",
    "https://stackabuse.com/example-upload-a-file-to-aws-s3-with-boto/ \\\n",
    "https://stackoverflow.com/questions/490195/split-a-multi-page-pdf-file-into-multiple-pdf-files-with-python \\\n",
    "https://programtalk.com/python-examples/pdfminer.pdfpage.PDFPage.create_pages/ \\\n",
    "https://www.analyticsvidhya.com/blog/2021/09/pypdf2-library-for-working-with-pdf-files-in-python/ \\\n",
    "https://realpython.com/pdf-python/  \\\n",
    "https://stackabuse.com/example-upload-a-file-to-aws-s3-with-boto/ \\\n",
    "https://www.blog.pythonlibrary.org/2018/04/11/splitting-and-merging-pdfs-with-python/\n",
    "https://stackoverflow.com/questions/62799852/read-pdf-object-from-s3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Problem statement\n",
    "\n",
    "Casting product image data for quality inspection\n",
    "\n",
    "####  Tasks \n",
    "1. Download Data from Kaggle through s3\n",
    "2. Stored data in s3 \n",
    "3. Use Image libraries to visualize sample images\n",
    "\n",
    "\n",
    "#### Reference\n",
    "https://blog.jovian.ai/metal-casting-product-image-classification-for-quality-inspection-using-pytorch-72c696d205f3\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/detect-manufacturing-defects-in-real-time-using-amazon-lookout-for-vision/\n",
    "\n",
    "https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product\n",
    "https://www.kaggle.com/souvikg544/souvik-ghosh-casting\n",
    "\n",
    "\n",
    "https://sagemakerexamples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-fulltraining-highlevel.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Amazon SageMaker and ðŸ¤— Transformers: Train and Deploy a Summarization Model with a Custom Dataset\n",
    "\n",
    "#### Reference \n",
    "https://towardsdatascience.com/amazon-sagemaker-and-transformers-train-and-deploy-a-summarization-model-with-a-custom-dataset-5efc589fedad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
