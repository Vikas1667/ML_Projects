{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "85d28486-2eb7-48de-8061-7b46ee02cc07",
    "_uuid": "665ce745c4fd314ff71cf8f8d5f2056df97ff9d2"
   },
   "source": [
    "In this kernel I want to build a simple EDA (exploratory data analysis) pipeline that can be applied to any datasets with only some slight tweaks neccessary. At the moment, this is based on a continuous **target** variable, i.e. for regression. I will add a pipeline for **categorical** target variables soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "601252c6-f84a-47e7-a432-b62e73effb56",
    "_uuid": "4d50a9a6f2117c7643fa83d5da63cfca91b01a40"
   },
   "source": [
    "# Read in the Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "# Data Vis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', palette='deep') \n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e46dff88-c60c-48cf-aff8-ca46390ef507",
    "_uuid": "ee0159d8bbed7fe6b3dd6867d9402e448c69001c"
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "\n",
    "# Change the settings so that you can see all columns of the dataframe when calling df.head()\n",
    "pd.set_option('display.max_columns',999)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a15858ab-6a52-4f2d-815b-4c7e6b005f12",
    "_uuid": "c1878502cbb460fba87b09f6ca026499e5d99d53"
   },
   "source": [
    "# Data Types\n",
    "\n",
    "Below you can see the types of data in the dataset. Pandas usually does a good job at assigning the correct data type but sometimes it doesn't. If that's the case you can change the datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "e4a4e867-654b-4d1d-b781-df8686398e34",
    "_uuid": "29ed52d7f1aea6454148c864f821ab325a14c215",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "dff88a02-f04f-4588-908b-9a9080b69999",
    "_uuid": "66e758cd885add13b91b31675157e81bdba600a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert data to object\n",
    "#object_train = []\n",
    "#train[object_train] = train[object_train].astype('object')\n",
    "\n",
    "# Convert data to numeric\n",
    "#numeric_train = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "#train[numeric_train] = train[numeric_train].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d2ea72bb-b7e9-4366-876b-3055cfe312c4",
    "_uuid": "a4e3780881c28378974fb84dd1b403f315587d8b"
   },
   "source": [
    "# Missing Data\n",
    "\n",
    "Not only can the data type be incorrect but there could also be missing data. Let's have a look at this visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "6c7bcf52-e2b5-491e-a128-1975c235f766",
    "_kg_hide-input": true,
    "_uuid": "429bba220fb18414d6fd04039a9650190adb357a"
   },
   "outputs": [],
   "source": [
    "# Capture the necessary data\n",
    "variables = train.columns\n",
    "\n",
    "count = []\n",
    "\n",
    "for variable in variables:\n",
    "    length = train[variable].count()\n",
    "    count.append(length)\n",
    "    \n",
    "count_pct = np.round(100 * pd.Series(count) / len(train), 2)\n",
    "count = pd.Series(count)\n",
    "\n",
    "missing = pd.DataFrame()\n",
    "missing['variables'] = variables\n",
    "missing['count'] = len(train) - count\n",
    "missing['count_pct'] = 100 - count_pct\n",
    "missing = missing[missing['count_pct'] > 0]\n",
    "missing.sort_values(by=['count_pct'], inplace=True)\n",
    "missing_train = np.array(missing['variables'])\n",
    "\n",
    "#Plot number of available data per variable\n",
    "plt.subplots(figsize=(15,6))\n",
    "\n",
    "# Plots missing data in percentage\n",
    "plt.subplot(1,2,1)\n",
    "plt.barh(missing['variables'], missing['count_pct'])\n",
    "plt.title('Count of missing training data in percent', fontsize=15)\n",
    "\n",
    "# Plots total row number of missing data\n",
    "plt.subplot(1,2,2)\n",
    "plt.barh(missing['variables'], missing['count'])\n",
    "plt.title('Count of missing training data as total records', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "36275c01-7540-4017-82e0-a26441912dc1",
    "_uuid": "7e089709cda4578d4547ec308f4404f8f69b394e"
   },
   "source": [
    "# Target is Continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a00c91e7-8609-4b2e-aaef-d7fa6117a4ab",
    "_uuid": "5dd9e76f91774efc9119f442abbe21f8c8783d62"
   },
   "source": [
    "## Get the Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "568df327-fbfd-4292-9d2f-4cdfb6c4f0d1",
    "_kg_hide-input": false,
    "_uuid": "1343562dbef14a65b0eea828d624f013db67a39b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get target\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Get quantitative features and delete the unnccessary features\n",
    "quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\n",
    "quantitative.remove('SalePrice')\n",
    "quantitative.remove('Id')\n",
    "\n",
    "# Get categorical features\n",
    "categorical = [f for f in train.columns if train.dtypes[f] == 'object']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "792c08c8-7efd-4389-bd85-47dceff5f987",
    "_uuid": "75021ad010984da0ce86862e5cf1d0d3650d84ab"
   },
   "source": [
    "## Histogram of Target\n",
    "\n",
    "Let's first look at the target variable. Because it is continuous/numeric a histogram is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "eca19ac2-cab8-45fb-b1b9-8b5cf6e61aa9",
    "_kg_hide-input": true,
    "_uuid": "87997910a12ce04a74c8c3b6ad44a1b00b556d48"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(train[target])\n",
    "plt.title('Histogram of %s' % target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d9e471cd-ffd0-47b5-b4ec-184acc2aaa68",
    "_uuid": "28e345a2d70b5d8237e32e3b70e761112b575876"
   },
   "source": [
    "## Quantitative Features\n",
    "\n",
    "Next up are the quantitative featuires. I have plotted histograms and scatterplots against the target variable. This gives you an idea how the features are distributed and how they interact with the target variable. Skewed histograms may inidcate that you have to log-transform thet particular feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7eb0430d-0b42-4b05-8127-6556d0665031",
    "_uuid": "41916ad1e88b0cde452cc85fc0e1b49f840eb7ee"
   },
   "source": [
    "**Histograms of Quantitative Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "d83379b6-4bc6-4e42-8abe-e72260cf1e3c",
    "_kg_hide-input": true,
    "_uuid": "89af1c96f37352319ab5effdbdb56e5d7c7616fc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = pd.melt(train, value_vars=quantitative)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False, size=5)\n",
    "g = g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f382ec4a-8b83-4fe3-a6c7-5395b6c63c5d",
    "_uuid": "4d8d9a7b59f71c988b0dbffe45d05b73734bbeb5"
   },
   "source": [
    "**Scatterplot of Quantitative Features against Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "d6e17b65-9140-4d06-8732-d4b4bc066c5b",
    "_kg_hide-input": true,
    "_uuid": "edfd57622b97495308c74034bd1e47fcf1ca62e8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = pd.melt(train, id_vars=[target], value_vars=quantitative)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False, size=5)\n",
    "g = g.map(sns.regplot, \"value\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7990af8d-3ac7-48bb-a38c-7d02651c13ee",
    "_uuid": "fa9938193ef397d834058d2f68b01238f40e81fd"
   },
   "source": [
    "## Categorical Features\n",
    "\n",
    "Histograms and scatterplots don't work for categorical features. Instead I use countplots and box-whisker plots that try to get at the same thing. You get an idea of how a feature is distributed - are the categories within a feature balanced or not; do the different categories have different/distinct target values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "036048af-1178-44ef-8eff-2b8a4ba4816c",
    "_uuid": "e09e6b62385c5a54cd5fdb0230f749996003420d"
   },
   "source": [
    "**Countplots of Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "1f1a92cd-ad0f-4c91-81cf-94070a6f82a9",
    "_kg_hide-input": true,
    "_uuid": "89365cb71f60b4c640248d8a403de3b352d47ede"
   },
   "outputs": [],
   "source": [
    "def countplot(x, **kwargs):\n",
    "    sns.countplot(x=x)\n",
    "    x=plt.xticks(rotation=90)\n",
    "f = pd.melt(train, value_vars=categorical)\n",
    "g = sns.FacetGrid(f, col='variable',  col_wrap=3, sharex=False, sharey=False, size=5)\n",
    "g = g.map(countplot, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "408f85ad-337d-4c48-9a2c-c4ce3443336f",
    "_uuid": "d463c85ae2d6008bf92a842e6311f373faa9b53a"
   },
   "source": [
    "**Box-whisker Plots of Categorical Features against Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "747a1673-17af-45e2-9f2b-f0c853c04d07",
    "_kg_hide-input": true,
    "_uuid": "44e8daf04ac395d697586e1675142235c4ecc47f"
   },
   "outputs": [],
   "source": [
    "def boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "f = pd.melt(train, id_vars=[target], value_vars=categorical)\n",
    "g = sns.FacetGrid(f, col='variable',  col_wrap=3, sharex=False, sharey=False, size=5)\n",
    "g = g.map(boxplot, 'value', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "931ad59e-7296-4250-bdce-1aeaea879c1f",
    "_uuid": "f14ab01b12da8e3f151227ed582389ee71d079ad"
   },
   "source": [
    "## Correlation Matrix of Numeric Features\n",
    "\n",
    "We already got an idea of the correlations between the quantitative features and the target from the scatterplots but we also need to check how all features correlated with each other. A correlation matrix is a good choice for that. On thing we can learn from the matrix is whether some features are highly correlated with each, which can affect the coefficients and significance of them if you wanted to look at them. If that is the case, you might to drop one of them or use PCA to reduce the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "6084f0f9-4d47-41bf-8fc2-be2b3aa97b36",
    "_uuid": "1f3c16ebec32bf504e27a777f3d1a39a22b41891"
   },
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "# Compute the correlation matrix\n",
    "d= train\n",
    "corr = d.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, \n",
    "            square=True, linewidths=.5, annot=False, cmap=cmap)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlation Matrix of all Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "48d47489-7168-49a6-9124-4cc5bfcbc071",
    "_uuid": "35708a3888dfb1bbc1d8356046848466612a7b22",
    "collapsed": true
   },
   "source": [
    "Do you have comments or suggestion or maybe you managed to apply the code to a different data set, please let me know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ce9b6bc4-7f06-467b-b792-69cc19887ab2",
    "_uuid": "8a4e0172037d6959a4044d7d2ec71690acf14fac",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
